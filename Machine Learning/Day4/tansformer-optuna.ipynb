{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ccae883-1904-48a6-81b3-d0228caeab1f",
      "metadata": {
        "id": "9ccae883-1904-48a6-81b3-d0228caeab1f"
      },
      "source": [
        "### Multivariate time series prediction using transformer with hyperparameter optimization\n",
        "\n",
        "In this notebook, we use **Optuna** to find the optimum values of hyperparameters. In this notebook we specifically optimize the values of **learning rate, weight decay, positional encoding dropout** and **encoder layer dropout**.\n",
        "\n",
        "Optuna is a python package specifially designed for hyperparameter tuning. We need to define a range of possible values for each of the hyperparameters. And optuna will try different parameter values with the model to minimize the validation loss after for specified number of experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e04f754c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04f754c",
        "outputId": "ded798c2-97ea-48f9-b1f0-faacaa88d475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.42)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4117e9d0-7925-4788-bbe1-28c60c80bb56",
      "metadata": {
        "id": "4117e9d0-7925-4788-bbe1-28c60c80bb56"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8af4f85b-3822-4288-9566-0f0ac0cfa053",
      "metadata": {
        "id": "8af4f85b-3822-4288-9566-0f0ac0cfa053"
      },
      "outputs": [],
      "source": [
        "path = 'final_data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fc9eb646-4308-449c-84c0-00cd1de182c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc9eb646-4308-449c-84c0-00cd1de182c2",
        "outputId": "a3a55176-b680-43c8-e549-eb06757fdfff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Implement determinism. Set a fixed value for random seed so that when the parameters are initialized, they are initialized same across all experiments.\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# If you are using CUDA, also set the seed for it\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Set the seed for NumPy\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0600e784-ec1c-4ab8-ab6b-9b765b4dee83",
      "metadata": {
        "id": "0600e784-ec1c-4ab8-ab6b-9b765b4dee83"
      },
      "source": [
        "Here we define **RiverData** a custom Dataset class to load the dataset we have. It extends the Pytorch Dataset class.  \n",
        "- We need to define \\_\\_init__() function which can be used for loading data from the file and optionally for data preprocessing.\n",
        "- Thereafter we define \\_\\_len__() function which gives the length of dataset.\n",
        "- Then we define \\_\\_getitem__() function which returns an instance of (feature, label) tuple which can be used for model training.\n",
        "  For our time series data, feature means the past values to be used for training and label means the future values to be predicted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "742b694d-9966-4fd3-bca7-51f398a8775f",
      "metadata": {
        "id": "742b694d-9966-4fd3-bca7-51f398a8775f"
      },
      "outputs": [],
      "source": [
        "class RiverData(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, target, datecol, seq_len, pred_len):\n",
        "        self.df = df\n",
        "        self.datecol = datecol\n",
        "        self.target = target\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        self.setIndex()\n",
        "\n",
        "\n",
        "    def setIndex(self):\n",
        "        self.df.set_index(self.datecol, inplace=True)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) - self.seq_len - self.pred_len\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if len(self.df) <= (idx + self.seq_len+self.pred_len):\n",
        "            raise IndexError(f\"Index {idx} is out of bounds for dataset of size {len(self.df)}\")\n",
        "        df_piece = self.df[idx:idx+self.seq_len].values\n",
        "        feature = torch.tensor(df_piece, dtype=torch.float32)\n",
        "        label_piece = self.df[self.target][idx + self.seq_len:  idx+self.seq_len+self.pred_len].values\n",
        "        label = torch.tensor(label_piece, dtype=torch.float32)\n",
        "        return (feature, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c24959-e72f-435d-8a14-69a648fa5ab1",
      "metadata": {
        "id": "60c24959-e72f-435d-8a14-69a648fa5ab1"
      },
      "source": [
        "### Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "46d897d9-946e-4bbe-90a6-cc8d8a223c3f",
      "metadata": {
        "id": "46d897d9-946e-4bbe-90a6-cc8d8a223c3f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path)\n",
        "raw_df = df.drop('DATE', axis=1, inplace=False)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Apply the transformations\n",
        "df_scaled = scaler.fit_transform(raw_df)\n",
        "\n",
        "df_scaled = pd.DataFrame(df_scaled, columns=raw_df.columns)\n",
        "df_scaled['DATE'] = df['DATE']\n",
        "df = df_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4781c6-88ed-4b28-aa0e-f669bf7c75f5",
      "metadata": {
        "id": "3a4781c6-88ed-4b28-aa0e-f669bf7c75f5"
      },
      "source": [
        "Some advanced Python syntax has been used here. \\\n",
        "*common_args : it's used to pass arguments to a function, where common_args represents a python list \\\n",
        "**common_args: it's used to pass arguments to a function, where common_args represents a python dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9e63a535-a817-4429-be17-f3e3a02e4f73",
      "metadata": {
        "id": "9e63a535-a817-4429-be17-f3e3a02e4f73"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_size = int(0.7 * len(df))\n",
        "test_size = int(0.2 * len(df))\n",
        "val_size = len(df) - train_size - test_size\n",
        "\n",
        "seq_len = 13\n",
        "pred_len = 1\n",
        "num_features = 7\n",
        "num_layers = 1\n",
        "\n",
        "\n",
        "common_args = ['gauge_height', 'DATE', seq_len, pred_len]\n",
        "train_dataset = RiverData(df[:train_size], *common_args)\n",
        "val_dataset = RiverData(df[train_size: train_size+val_size], *common_args)\n",
        "test_dataset = RiverData(df[train_size+val_size : len(df)], *common_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "501879b1-dd1c-4ff0-afb3-ff25a345df05",
      "metadata": {
        "id": "501879b1-dd1c-4ff0-afb3-ff25a345df05"
      },
      "outputs": [],
      "source": [
        "# Important parameters\n",
        "\n",
        "BATCH_SIZE = 128 # keep as big as can be handled by GPU and memory\n",
        "SHUFFLE = False # we don't shuffle the time series data\n",
        "DATA_LOAD_WORKERS = 1 # it depends on amount of data you need to load\n",
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ae359aec-9435-4229-8587-5f120b0370b3",
      "metadata": {
        "id": "ae359aec-9435-4229-8587-5f120b0370b3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "common_args = {'batch_size': BATCH_SIZE, 'shuffle': SHUFFLE}\n",
        "train_loader = DataLoader(train_dataset, **common_args)\n",
        "val_loader = DataLoader(val_dataset, **common_args)\n",
        "test_loader = DataLoader(test_dataset, **common_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7ac35c-8ecc-4ab7-a97c-0cb4d59bc624",
      "metadata": {
        "id": "bc7ac35c-8ecc-4ab7-a97c-0cb4d59bc624"
      },
      "source": [
        "### Here we define our PyTorch model.\n",
        "\n",
        "BasicTransformerNetwork is the model class, it extends the Module class provided by Pytorch. \\\n",
        "- We define \\_\\_init__() function. It sets up layers and defines the model parameters.\n",
        "- Also, we define forward() function which defines how the forwared pass computation occurs\n",
        "- We also implement PositionalEncoding class which is an important part of transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "01cd8d0d-2058-4dfe-9046-78cde5fd2f58",
      "metadata": {
        "id": "01cd8d0d-2058-4dfe-9046-78cde5fd2f58"
      },
      "outputs": [],
      "source": [
        "# The transformer implementation in pytorch doesn't implement the\n",
        "# positional encoding which is an essential part of the transforemer model\n",
        "\n",
        "# Provide more description of positional encoding\n",
        "class PositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, d_model, pos_enc_dropout, max_len=5000):\n",
        "        super().__init__();\n",
        "        self.dropout = torch.nn.Dropout(p=pos_enc_dropout)\n",
        "\n",
        "        Xp = torch.zeros(max_len, d_model) # max_len x d_model\n",
        "        position = torch.arange(0, max_len).unsqueeze(1) # max_len x 1\n",
        "\n",
        "        # Generates an exponentially decreasing series of numbers\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)) #length: d_model/2\n",
        "\n",
        "        #Applying sine to even indices in the array; 2i\n",
        "        Xp[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "\n",
        "        #Applying cosine to odd indices in the array; 2i + 1\n",
        "        Xp[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "\n",
        "        Xp = Xp.unsqueeze(1)\n",
        "        self.register_buffer('Xp', Xp)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x  = x + self.Xp[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "class BasicTransformerNetwork(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, seq_len, pred_len, enc_layer_dropout, pos_enc_dropout):\n",
        "        # call the constructor of the base class\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        self.num_features = num_features\n",
        "\n",
        "        # I don't think the embedding size should be this big. We will see.\n",
        "        self.embedding_size = 128 #The features are converted to 128 embeddings\n",
        "        self.num_layers = num_layers\n",
        "        self.pos_encoder = PositionalEncoding(self.embedding_size, pos_enc_dropout, 10000)\n",
        "\n",
        "        # dim_feedforward = 4 * d_model\n",
        "        # layer_norm_eps: A very small number (epsilon) added to the denominator during the Layer Normalization calculation.\n",
        "        self.encLayer = torch.nn.TransformerEncoderLayer(d_model=self.embedding_size, nhead=8,\n",
        "                                                 dim_feedforward=256, dropout=enc_layer_dropout, activation=\"relu\",\n",
        "                                                 layer_norm_eps=1e-05, batch_first=True)\n",
        "\n",
        "        self.transformerEnc = torch.nn.TransformerEncoder(self.encLayer, num_layers=self.num_layers)\n",
        "\n",
        "        self.input_fc = torch.nn.Linear(self.num_features, self.embedding_size)\n",
        "\n",
        "        self.prediction_head = torch.nn.Linear(self.embedding_size, self.pred_len)\n",
        "\n",
        "        # Create causal mask\n",
        "        self.register_buffer('causal_mask', self._generate_causal_mask(seq_len))\n",
        "\n",
        "\n",
        "    def _generate_causal_mask(self, seq_len):\n",
        "        \"\"\"\n",
        "        Generate causal mask for transformer encoder.\n",
        "        Returns upper triangular matrix with -inf in upper triangle (excluding diagonal)\n",
        "        \"\"\"\n",
        "        mask = torch.triu(torch.full((seq_len, seq_len), float('-inf')), diagonal=1)\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_fc(x) * np.sqrt(self.embedding_size)\n",
        "        x = self.pos_encoder(x)\n",
        "        out = self.transformerEnc(x, mask=self.causal_mask)\n",
        "        last_embedding = out[:, -1, :]\n",
        "        prediction = self.prediction_head(last_embedding)\n",
        "        prediction = prediction.squeeze(-1)\n",
        "        return prediction\n",
        "# Note that the gradients are stored inside the FC layer objects\n",
        "# For each training example we need to get rid of these gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f579dc18-584e-414b-ae8e-37f62e4b42f3",
      "metadata": {
        "id": "f579dc18-584e-414b-ae8e-37f62e4b42f3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b600c877-3409-48f9-80e5-3fdde7731817",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b600c877-3409-48f9-80e5-3fdde7731817",
        "outputId": "bbc5643a-997a-433e-9492-dfae80f53329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5277794b-fe37-4595-8554-d26db5710e44",
      "metadata": {
        "id": "5277794b-fe37-4595-8554-d26db5710e44"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1afde643-9953-4129-8415-7b4836c31300",
      "metadata": {
        "id": "1afde643-9953-4129-8415-7b4836c31300"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4b3cc7a8-9844-4eae-a601-4787513eb1cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b3cc7a8-9844-4eae-a601-4787513eb1cf",
        "outputId": "d54a123d-6f88-40ba-ed64-44c75cdd94f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features shape:  torch.Size([128, 13, 7])\n",
            "labels shape:  torch.Size([128, 1])\n"
          ]
        }
      ],
      "source": [
        "for i, (f,l) in enumerate(train_loader):\n",
        "    print('features shape: ', f.shape)\n",
        "    print('labels shape: ', l.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "22683e91-642a-494b-abc5-069dc6fa9eb6",
      "metadata": {
        "id": "22683e91-642a-494b-abc5-069dc6fa9eb6"
      },
      "outputs": [],
      "source": [
        "# define metrics\n",
        "import numpy as np\n",
        "epsilon = np.finfo(float).eps\n",
        "\n",
        "def wape_function(y, y_pred):\n",
        "    \"\"\"Weighted Average Percentage Error metric in the interval [0; 100]\"\"\"\n",
        "    y = np.array(y)\n",
        "    y_pred = np.array(y_pred)\n",
        "    nominator = np.sum(np.abs(np.subtract(y, y_pred)))\n",
        "    denominator = np.add(np.sum(np.abs(y)), epsilon)\n",
        "    wape = np.divide(nominator, denominator) * 100.0\n",
        "    return wape\n",
        "\n",
        "def nse_function(y, y_pred):\n",
        "    y = np.array(y)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return (1-(np.sum((y_pred-y)**2)/np.sum((y-np.mean(y))**2)))\n",
        "\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    # following line prepares the model for evaulation mode. It disables dropout and batch normalization if they have\n",
        "    # are part of the model. For our simple model it's not necessary. Still I'm going to use it.\n",
        "\n",
        "    model.eval()\n",
        "    all_outputs = torch.empty(0, pred_len)\n",
        "    all_labels = torch.empty(0, pred_len)\n",
        "    for inputs, labels in data_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs).detach().cpu().unsqueeze(1)\n",
        "        all_outputs = torch.vstack((all_outputs, outputs))\n",
        "        all_labels = torch.vstack((all_labels, labels))\n",
        "\n",
        "    avg_val_loss = loss(all_outputs, all_labels)\n",
        "    nse = nse_function(all_labels.numpy(), all_outputs.numpy())\n",
        "    wape = wape_function(all_labels.numpy(), all_outputs.numpy())\n",
        "\n",
        "    print(f'NSE : {nse}', end=' ')\n",
        "    print(f'WAPE : {wape}', end=' ')\n",
        "    print(f'Validation Loss: {avg_val_loss}')\n",
        "    model.train()\n",
        "    return avg_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9beaf3a1-2c40-4fc6-b0f7-c352b5763231",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9beaf3a1-2c40-4fc6-b0f7-c352b5763231",
        "outputId": "d25bd783-de00-4d6c-d559-6e666043d2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:31:29,270] A new study created in memory with name: no-name-c46b8941-c00e-4fcc-ae8c-34999764cec1\n",
            "/tmp/ipython-input-2185253866.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-2185253866.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
            "/tmp/ipython-input-2185253866.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  pos_enc_dropout = trial.suggest_uniform('pos_enc_dropout', 0.05, 0.3)\n",
            "/tmp/ipython-input-2185253866.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  enc_layer_dropout = trial.suggest_uniform('enc_layer_dropout', 0.1, 0.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Traning Loss: 0.010006823082036768 NSE : 0.9315107464790344 WAPE : 14.171068265246042 Validation Loss: 0.0011692815460264683\n",
            "Epoch 2: Traning Loss: 0.002375987787441655 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:33:34,600] Trial 0 finished with value: 0.0011692815460264683 and parameters: {'lr': 0.00032072699377992247, 'weight_decay': 0.0001531564603267, 'pos_enc_dropout': 0.07535993990784572, 'enc_layer_dropout': 0.15363490125391033}. Best is trial 0 with value: 0.0011692815460264683.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.9142634272575378 WAPE : 16.99980992630176 Validation Loss: 0.0014637359417974949\n",
            "Early stopping!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2185253866.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-2185253866.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
            "/tmp/ipython-input-2185253866.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  pos_enc_dropout = trial.suggest_uniform('pos_enc_dropout', 0.05, 0.3)\n",
            "/tmp/ipython-input-2185253866.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  enc_layer_dropout = trial.suggest_uniform('enc_layer_dropout', 0.1, 0.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Traning Loss: 0.028059279007702272 NSE : 0.6078922748565674 WAPE : 30.40609126777308 Validation Loss: 0.006694253068417311\n",
            "Epoch 2: Traning Loss: 0.009068501000842872 NSE : 0.7940086126327515 WAPE : 21.68404812430098 Validation Loss: 0.003516784170642495\n",
            "Epoch 3: Traning Loss: 0.006260462261480782 NSE : 0.8725645542144775 WAPE : 17.799373998129372 Validation Loss: 0.0021756396163254976\n",
            "Epoch 4: Traning Loss: 0.004251745643669307 NSE : 0.9556660652160645 WAPE : 10.782927561056004 Validation Loss: 0.0007568903965875506\n",
            "Epoch 5: Traning Loss: 0.003060955604540688 NSE : 0.9730830192565918 WAPE : 8.530354501093077 Validation Loss: 0.0004595394420903176\n",
            "Epoch 6: Traning Loss: 0.0023773107624445893 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:39:27,711] Trial 1 finished with value: 0.0004595394420903176 and parameters: {'lr': 0.00012848090154765035, 'weight_decay': 0.008272247102142354, 'pos_enc_dropout': 0.23441675293458603, 'enc_layer_dropout': 0.37091218007195526}. Best is trial 1 with value: 0.0004595394420903176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.9684913754463196 WAPE : 9.316139000129592 Validation Loss: 0.0005379306385293603\n",
            "Early stopping!\n",
            "Epoch 1: Traning Loss: 0.013431153069055027 NSE : 0.923073410987854 WAPE : 14.70358275275312 Validation Loss: 0.0013133283937349916\n",
            "Epoch 2: Traning Loss: 0.004024859980219712 NSE : 0.9489800930023193 WAPE : 11.722738114187193 Validation Loss: 0.0008710368419997394\n",
            "Epoch 3: Traning Loss: 0.002255519977554778 NSE : 0.9622312784194946 WAPE : 11.085308931826313 Validation Loss: 0.0006448063068091869\n",
            "Epoch 4: Traning Loss: 0.0015543173109429736 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:46:42,702] Trial 2 finished with value: 0.0006448063068091869 and parameters: {'lr': 0.00040311774446738513, 'weight_decay': 0.005661330677817171, 'pos_enc_dropout': 0.2213006992522944, 'enc_layer_dropout': 0.16626724017062594}. Best is trial 1 with value: 0.0004595394420903176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.9303076863288879 WAPE : 15.93773902273771 Validation Loss: 0.0011898207012563944\n",
            "Early stopping!\n",
            "Epoch 1: Traning Loss: 0.018909776522813476 NSE : 0.6467713117599487 WAPE : 36.01832313972521 Validation Loss: 0.006030491553246975\n",
            "Epoch 2: Traning Loss: 0.0035173964732991628 NSE : 0.9676641225814819 WAPE : 9.274709492733004 Validation Loss: 0.0005520538543350995\n",
            "Epoch 3: Traning Loss: 0.0017704667425578345 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:49:40,774] Trial 3 finished with value: 0.0005520538543350995 and parameters: {'lr': 0.0013961913765743723, 'weight_decay': 0.0015723657375944652, 'pos_enc_dropout': 0.28623544054173317, 'enc_layer_dropout': 0.3144256707362448}. Best is trial 1 with value: 0.0004595394420903176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.9601106643676758 WAPE : 10.722478578632582 Validation Loss: 0.0006810097256675363\n",
            "Early stopping!\n",
            "Epoch 1: Traning Loss: 0.043656390770467166 NSE : -0.009039998054504395 WAPE : 46.06182527798829 Validation Loss: 0.017226818948984146\n",
            "Epoch 2: Traning Loss: 0.010429214625830512 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:52:45,164] Trial 4 finished with value: 0.017226818948984146 and parameters: {'lr': 0.007206751027795621, 'weight_decay': 0.00542839291705587, 'pos_enc_dropout': 0.1355121515259291, 'enc_layer_dropout': 0.2795174955473122}. Best is trial 1 with value: 0.0004595394420903176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : -0.5473182201385498 WAPE : 74.73916148534627 Validation Loss: 0.026416562497615814\n",
            "Early stopping!\n",
            "Epoch 1: Traning Loss: 0.011977338940059007 NSE : 0.8879748582839966 WAPE : 17.80074958939151 Validation Loss: 0.0019125478575006127\n",
            "Epoch 2: Traning Loss: 0.004282654620608815 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:54:42,783] Trial 5 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.945041835308075 WAPE : 12.874851920351812 Validation Loss: 0.000938272278290242\n",
            "Epoch 1: Traning Loss: 0.009021002049895128 NSE : 0.9116544127464294 WAPE : 17.425707287209015 Validation Loss: 0.0015082784229889512\n",
            "Epoch 2: Traning Loss: 0.0018455694137280748 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:56:40,511] Trial 6 finished with value: 0.0015082784229889512 and parameters: {'lr': 0.0005084408918349834, 'weight_decay': 4.347610569089164e-05, 'pos_enc_dropout': 0.09055552118899875, 'enc_layer_dropout': 0.13959939247510922}. Best is trial 1 with value: 0.0004595394420903176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.9088083505630493 WAPE : 17.98112371852119 Validation Loss: 0.0015568681992590427\n",
            "Early stopping!\n",
            "Epoch 1: Traning Loss: 0.016607667804219947 NSE : 0.937149167060852 WAPE : 13.511306083626087 Validation Loss: 0.0010730195790529251\n",
            "Epoch 2: Traning Loss: 0.003192302869207414 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:58:39,339] Trial 7 finished with value: 0.0010730195790529251 and parameters: {'lr': 0.001741870046581205, 'weight_decay': 0.0007050961140663397, 'pos_enc_dropout': 0.2002277120947007, 'enc_layer_dropout': 0.15440488819050646}. Best is trial 1 with value: 0.0004595394420903176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.8811115026473999 WAPE : 20.161770412805915 Validation Loss: 0.0020297225564718246\n",
            "Early stopping!\n",
            "Epoch 1: Traning Loss: 0.012903459594387377 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 18:59:37,691] Trial 8 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSE : 0.40200990438461304 WAPE : 47.105967275278125 Validation Loss: 0.010209174826741219\n"
          ]
        }
      ],
      "source": [
        "from optuna.samplers import TPESampler\n",
        "def objective(trial):\n",
        "    # Here we define the search space of the hyper-parameters. Optuna uses byaesian optimization to find the optimal values of the hyperparameters.\n",
        "    learning_rate = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
        "    pos_enc_dropout = trial.suggest_uniform('pos_enc_dropout', 0.05, 0.3)\n",
        "    enc_layer_dropout = trial.suggest_uniform('enc_layer_dropout', 0.1, 0.5)\n",
        "\n",
        "\n",
        "    model = BasicTransformerNetwork(seq_len, pred_len, pos_enc_dropout, enc_layer_dropout)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    num_epochs = 10\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = []\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs).unsqueeze(1)\n",
        "            loss_val = loss(outputs, labels)\n",
        "\n",
        "            # calculate gradients for back propagation\n",
        "            loss_val.backward()\n",
        "\n",
        "            # update the weights based on the gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # reset the gradients, avoid gradient accumulation\n",
        "            optimizer.zero_grad()\n",
        "            epoch_loss.append(loss_val.item())\n",
        "\n",
        "        avg_train_loss = sum(epoch_loss)/len(epoch_loss)\n",
        "        print(f'Epoch {epoch+1}: Traning Loss: {avg_train_loss}', end=' ')\n",
        "        avg_val_loss = evaluate_model(model, val_loader)\n",
        "\n",
        "        # Check for improvement\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), 'best_model_trial.pth')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print('Early stopping!')\n",
        "                # Load the best model before stopping\n",
        "                model.load_state_dict(torch.load('best_model_trial.pth'))\n",
        "                break\n",
        "\n",
        "        # Report intermediate objective value\n",
        "        trial.report(best_val_loss, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "# Default sampler is TPESampler (Tree-structured Parzen Estimator).\n",
        "# This sampler is based on independent sampling and uses a Bayesian optimization approach to efficiently explore\n",
        "# the hyperparameter search space by building probability models of objective values.\n",
        "\n",
        "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "\n",
        "# normally you run 100s of trials.\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "\n",
        "print('  Value (Best Validation Loss):', trial.value)\n",
        "print('  Params:')\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7216e93-a35d-4aa5-83db-2e43ea380f6e",
      "metadata": {
        "id": "f7216e93-a35d-4aa5-83db-2e43ea380f6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "722fee71-de14-463f-abf6-e35f9f002ae1",
      "metadata": {
        "id": "722fee71-de14-463f-abf6-e35f9f002ae1"
      },
      "outputs": [],
      "source": [
        "# Plot the results with the metrics inside it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a2f592f-d2be-4ea2-9e9e-d034d45f551d",
      "metadata": {
        "id": "9a2f592f-d2be-4ea2-9e9e-d034d45f551d"
      },
      "outputs": [],
      "source": [
        "import optuna.visualization as vis\n",
        "\n",
        "# Optimization history\n",
        "fig1 = vis.plot_optimization_history(study)\n",
        "fig1.write_html(\"optimization_history_transformer.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c474aced-89cf-41c7-ae2c-b98c4b87b1b9",
      "metadata": {
        "id": "c474aced-89cf-41c7-ae2c-b98c4b87b1b9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}